{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing Simulations\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Questions\n",
    "\n",
    "* How do I continue running a simulation?\n",
    "\n",
    "### Objectives\n",
    "\n",
    "* Explain why you may want to **continue** running a simulation, such as **wall time** limits for **cluster jobs**.\n",
    "* Describe what you need to consider when writing a **workflow step** that can **continue**.\n",
    "* Demonstrate how to **append** to trajectory files, write needed data to a **restart** file and limit the simulation run to a given **wall time**.\n",
    "\n",
    "## Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import flow\n",
    "import hoomd\n",
    "import signac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow steps from the previous section\n",
    "\n",
    "The code in the next block collects the workflow steps the previous tutorial section to define the whole workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simulation(job):\n",
    "    cpu = hoomd.device.CPU()\n",
    "    sim = hoomd.Simulation(device=cpu, seed=job.statepoint.seed)\n",
    "    mc = hoomd.hpmc.integrate.ConvexPolyhedron()\n",
    "    mc.shape['octahedron'] = dict(vertices=[\n",
    "        (-0.5, 0, 0),\n",
    "        (0.5, 0, 0),\n",
    "        (0, -0.5, 0),\n",
    "        (0, 0.5, 0),\n",
    "        (0, 0, -0.5),\n",
    "        (0, 0, 0.5),\n",
    "    ])\n",
    "    sim.operations.integrator = mc\n",
    "\n",
    "    return sim\n",
    "\n",
    "\n",
    "class Project(flow.FlowProject):\n",
    "    pass\n",
    "\n",
    "\n",
    "@Project.pre.true('initialized')\n",
    "@Project.post.true('randomized')\n",
    "@Project.operation\n",
    "def randomize(job):\n",
    "    sim = create_simulation(job)\n",
    "    sim.create_state_from_gsd(filename=job.fn('lattice.gsd'))\n",
    "    sim.run(10e3)\n",
    "    hoomd.write.GSD.write(state=sim.state,\n",
    "                          mode='xb',\n",
    "                          filename=job.fn('random.gsd'))\n",
    "    job.document['randomized'] = True\n",
    "\n",
    "\n",
    "@Project.pre.after(randomize)\n",
    "@Project.post.true('compressed_step')\n",
    "@Project.operation\n",
    "def compress(job):\n",
    "    sim = create_simulation(job)\n",
    "    sim.create_state_from_gsd(filename=job.fn('random.gsd'))\n",
    "\n",
    "    a = math.sqrt(2) / 2\n",
    "    V_particle = 1 / 3 * math.sqrt(2) * a**3\n",
    "\n",
    "    initial_box = sim.state.box\n",
    "    final_box = hoomd.Box.from_box(initial_box)\n",
    "    final_box.volume = (sim.state.N_particles * V_particle\n",
    "                        / job.statepoint.volume_fraction)\n",
    "    compress = hoomd.hpmc.update.QuickCompress(\n",
    "        trigger=hoomd.trigger.Periodic(10), target_box=final_box)\n",
    "    sim.operations.updaters.append(compress)\n",
    "\n",
    "    periodic = hoomd.trigger.Periodic(10)\n",
    "    tune = hoomd.hpmc.tune.MoveSize.scale_solver(moves=['a', 'd'],\n",
    "                                                 target=0.2,\n",
    "                                                 trigger=periodic,\n",
    "                                                 max_translation_move=0.2,\n",
    "                                                 max_rotation_move=0.2)\n",
    "    sim.operations.tuners.append(tune)\n",
    "\n",
    "    while not compress.complete and sim.timestep < 1e6:\n",
    "        sim.run(1000)\n",
    "\n",
    "    if not compress.complete:\n",
    "        raise RuntimeError(\"Compression failed to complete\")\n",
    "\n",
    "    hoomd.write.GSD.write(state=sim.state,\n",
    "                          mode='xb',\n",
    "                          filename=job.fn('compressed.gsd'))\n",
    "    job.document['compressed_step'] = sim.timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Let's say your **workflow's** equilibration step takes 96 hours to complete and your HPC resource limits **wall times** to 24 hours.\n",
    "What do you do?\n",
    "\n",
    "One solution is to write the equilibration step so that it can **continue** where it left off.\n",
    "When you execute the workflow, each incomplete **signac job** will move toward completing the step's **post condition**.\n",
    "After several rounds of submissions, all **signac jobs** will be complete.\n",
    "\n",
    "This section of the tutorial teaches you how to write a **workflow step** that can limit its run time and **continue**.\n",
    "The next section will cover effectively run **workflow steps** in **cluster jobs** on HPC resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations\n",
    "\n",
    "You must carefully design your **workflow step** so that it can **continue** from where it left off:\n",
    "\n",
    "* Write the current state of the system to a GSD file and dynamic parameters to the **job document** (or other appropriate storage location).\n",
    "* Perform this write in a `finally:` block to ensure that it is written even when an exception is thrown.\n",
    "* Use the saved state when **continuing** the **workflow step**.\n",
    "* Open output files in **append** mode so that the final file includes output from the first and all **continued** executions.\n",
    "* Use absolute time step values for triggers so they run consistently before and after **continuing** the **workflow step**.\n",
    "* Check the elapsed **wall time** in a loop and stop executing before the **cluster job's** **wall time** limit.\n",
    "  Provide some buffer to write the simulation state and exit cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the equilibration code from the [Introducing HOOMD-blue](../00-Introducing-HOOMD-blue/00-index.ipynb) tutorial as a **signac-flow operation** that can **continue**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EQUIL_STEPS = 200000  # Number of timesteps to run during equilibration.\n",
    "HOOMD_RUN_WALLTIME_LIMIT = 30  # Time in seconds at which to stop the operation.\n",
    "\n",
    "\n",
    "@Project.pre.after(compress)  # Execute after compress completes.\n",
    "# Complete after N_EQUIL_STEPS made by this workflow step.\n",
    "@Project.post(lambda job: job.document.get('timestep', 0) - job.document[\n",
    "    'compressed_step'] >= N_EQUIL_STEPS)\n",
    "@Project.operation\n",
    "def equilibrate(job):\n",
    "    end_step = job.document['compressed_step'] + N_EQUIL_STEPS\n",
    "\n",
    "    sim = create_simulation(job)\n",
    "\n",
    "    # Restore the tuned move size parameters from a previous execution.\n",
    "    sim.operations.integrator.a = job.document.get('a', {})\n",
    "    sim.operations.integrator.d = job.document.get('d', {})\n",
    "\n",
    "    if job.isfile('restart.gsd'):\n",
    "        # Read the final system configuration from a previous execution.\n",
    "        sim.create_state_from_gsd(filename=job.fn('restart.gsd'))\n",
    "    else:\n",
    "        # Or read `compressed.gsd` for the first execution of equilibrate.\n",
    "        sim.create_state_from_gsd(filename=job.fn('compressed.gsd'))\n",
    "\n",
    "    # Write `trajectory.gsd` in append mode.\n",
    "    gsd_writer = hoomd.write.GSD(filename=job.fn('trajectory.gsd'),\n",
    "                                 trigger=hoomd.trigger.Periodic(10_000),\n",
    "                                 mode='ab')\n",
    "    sim.operations.writers.append(gsd_writer)\n",
    "\n",
    "    # Tune move for the first 5000 steps of the equilibration step.\n",
    "    tune = hoomd.hpmc.tune.MoveSize.scale_solver(\n",
    "        moves=['a', 'd'],\n",
    "        target=0.2,\n",
    "        trigger=hoomd.trigger.And([\n",
    "            hoomd.trigger.Periodic(100),\n",
    "            hoomd.trigger.Before(job.document['compressed_step'] + 5_000)\n",
    "        ]))\n",
    "    sim.operations.tuners.append(tune)\n",
    "\n",
    "    try:\n",
    "        # Loop until the simulation reaches the target timestep.\n",
    "        while sim.timestep < end_step:\n",
    "            # Run the simulation in chunks of 10,000 time steps.\n",
    "            sim.run(min(10_000, end_step - sim.timestep))\n",
    "\n",
    "            # End the workflow step early if the next run would exceed the\n",
    "            # alotted walltime. Use the walltime of the current run as\n",
    "            # an estimate for the next.\n",
    "            if (sim.device.communicator.walltime + sim.walltime >=\n",
    "                    HOOMD_RUN_WALLTIME_LIMIT):\n",
    "                break\n",
    "    finally:\n",
    "        # Write the state of the system to `restart.gsd`.\n",
    "        hoomd.write.GSD.write(state=sim.state,\n",
    "                              mode='wb',\n",
    "                              filename=job.fn('restart.gsd'))\n",
    "\n",
    "        # Store the current timestep and tuned trial move sizes.\n",
    "        job.document['timestep'] = sim.timestep\n",
    "        job.document['a'] = sim.operations.integrator.a.to_base()\n",
    "        job.document['d'] = sim.operations.integrator.d.to_base()\n",
    "\n",
    "        walltime = sim.device.communicator.walltime\n",
    "        sim.device.notice(f'{job.id} ended on step {sim.timestep} '\n",
    "                          f'after {walltime} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When this **workflow step** is executed, it  stores the trial move sizes `a`, `d` and the current timestep in the job document as well as the the state of the simulation in `restart.gsd`.\n",
    "It reads these when starting again to continue from where the previous execution stopped.\n",
    "This is a large code block, see the comments for more details on how this **workflow step** can **continue** from where it stopped.\n",
    "\n",
    "To limit the execution time, it splits the total simulation length into chunks and executes them in a loop.\n",
    "After each loop iteration, it checks to see whether the next call to `run` is likely to exceed the given time limit.\n",
    "`sim.device.communicator.walltime` gives the elapsed time from the start of the **workflow step's** execution, and is identical on all MPI ranks.\n",
    "Using another source of time might lead to deadlocks.\n",
    "As a pedagogical example, this tutorial sets a 30 second wall time limit and uses 10,000 timestep chunks - in practice you will likely set limits from hours to days and use larger 100,000 or 1,000,000 step sized chunks depending on your simulation's performance.\n",
    "You should set the chunk size large enough to avoid the small overhead from each call to `run` while at the same time breaking the complete execution into many chunks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *equilibrate* step is ready to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011934995651245117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 16,
       "postfix": null,
       "prefix": "Fetching status",
       "rate": null,
       "total": 9,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c6aa0123514c92a3239f9f3db4a235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching status:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008817434310913086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 16,
       "postfix": null,
       "prefix": "Fetching labels",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e9bf3426374544baffd8b3ef0f7bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching labels:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed View:\n",
      "\n",
      "job id                            operation/group      volume_fraction  labels\n",
      "--------------------------------  -----------------  -----------------  --------\n",
      "59363805e6f46a715bc154b38dffc4e4  equilibrate [U]                  0.6\n",
      "972b10bd6b308f65f0bc3a06db58cf9d  equilibrate [U]                  0.4\n",
      "c1a59a95a0e8b4526b28cf12aa0a689e  equilibrate [U]                  0.5\n",
      "\n",
      "[U]:unknown [R]:registered [I]:inactive [S]:submitted [H]:held [Q]:queued [A]:active [E]:error [GR]:group_registered [GI]:group_inactive [GS]:group_submitted [GH]:group_held [GQ]:group_queued [GA]:group_active [GE]:group_error\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project = Project()\n",
    "project.print_status(overview=False,\n",
    "                     detailed=True,\n",
    "                     parameters=['volume_fraction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972b10bd6b308f65f0bc3a06db58cf9d ended on step 32000 after 21.360734 seconds\n",
      "59363805e6f46a715bc154b38dffc4e4 ended on step 23000 after 15.127837 seconds\n",
      "c1a59a95a0e8b4526b28cf12aa0a689e ended on step 32000 after 25.856547 seconds\n"
     ]
    }
   ],
   "source": [
    "project.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *equilibrate* step executed for less than `HOOMD_RUN_WALLTIME_LIMIT` seconds for each of the **signac jobs** in the **dataspace**.\n",
    "In a production environment, you would run the project repeatedly until it completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that *equilibrate* step produced the `trajectory.gsd` file and the `'a'`, `'d'`, and `'timestep'` items in the **job document**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspace/59363805e6f46a715bc154b38dffc4e4:\n",
      "compressed.gsd\trandom.gsd   signac_job_document.json  trajectory.gsd\n",
      "lattice.gsd\trestart.gsd  signac_statepoint.json\n",
      "\n",
      "workspace/972b10bd6b308f65f0bc3a06db58cf9d:\n",
      "compressed.gsd\trandom.gsd   signac_job_document.json  trajectory.gsd\n",
      "lattice.gsd\trestart.gsd  signac_statepoint.json\n",
      "\n",
      "workspace/c1a59a95a0e8b4526b28cf12aa0a689e:\n",
      "compressed.gsd\trandom.gsd   signac_job_document.json  trajectory.gsd\n",
      "lattice.gsd\trestart.gsd  signac_statepoint.json\n"
     ]
    }
   ],
   "source": [
    "!ls workspace/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initialized': True, 'randomized': True, 'compressed_step': 13000, 'timestep': 23000, 'a': {'octahedron': 0.04564840324176478}, 'd': {'octahedron': 0.02567136340037109}}\n"
     ]
    }
   ],
   "source": [
    "job = project.open_job(dict(N_particles=128, volume_fraction=0.6, seed=20))\n",
    "print(job.document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this section of the tutorial, you defined the **workflow step** to *equilibreate* the hard particle simulation.\n",
    "It stores dynamic parameters and the state of the system needed to **continue** execution when executed again.\n",
    "Now, the **directory** for each simulation contains **trajectory.gsd**, and would be ready for analysis after executed to completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section in this tutorial will show you how to implement this workflow on the command line and submit **cluster jobs** that effectively use dense nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial only teaches the basics of **signac-flow**.\n",
    "Read the [signac-flow documentation](http://signac-flow.readthedocs.io/) to learn more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "record_timing": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
